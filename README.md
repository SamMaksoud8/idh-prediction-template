# IDH Prediction Platform ğŸ©¸  
**End-to-end MLOps prototype for predicting intradialytic hypotension (IDH) on Google Cloud**

This repository showcases a full machine-learning pipeline for clinical risk prediction of IDH â€” from **data ingestion** and **feature engineering** in BigQuery to **model deployment** on Vertex AI and a **Gradio web UI** for interactive inference â€” all in under one hour.

> ğŸ§  **Tech stack:** Python Â· BigQuery Â· Vertex AI Â· Cloud Storage Â· GitHub Actions Â· Gradio Â· Docker  
> âš™ï¸ **Focus:** reproducible MLOps, cloud orchestration, and interpretable healthcare AI  
> ğŸ©º **Dataset:** [Nature Scientific Data 2019 â€“ Blood pressure prediction for chronic hemodialysis](https://www.nature.com/articles/s41597-019-0319-8)

---

## ğŸš€ Quick Overview

This project demonstrates how to:

- **Provision** data infrastructure on Google Cloud (BigQuery + Cloud Storage)  
- **Engineer features** and **train models with (AUC = ~0.90)** directly within BigQuery  
- **Deploy** the trained model to **Vertex AI Endpoints** for online inference  
- **Interact** with predictions through a **Gradio web app** showing systolic BP trends and IDH risk  

The repository is organised as a Python package (`idh`) so components can be reused across CLI tools and the web UI.

![Architecture Diagram](docs/assets/architecture.png)

---

## ğŸ§© How to Use This Template

This repo is a **template**, designed for anyone to fork and reproduce the full pipeline within their own Google Cloud project.

### 1ï¸âƒ£ Fork the template
Click **Use this template** above to create your own copy. 
> âš ï¸ Keep the repository private to ensure your credentials remain secure.


### 2ï¸âƒ£ Add your Google Cloud credentials
1. Create a GCP service account with Vertex AI, BigQuery, and Storage permissions  
   (`roles/aiplatform.admin`, `roles/bigquery.admin`, `roles/storage.admin`).  
2. Download the JSON key.  
3. In your new repo, go to **Settings â†’ Secrets â†’ Actions â†’ New repository secret**  
   - Name: `GOOGLE_CLOUD_CREDENTIALS`  
   - Value: (contents of your key JSON)

### 3ï¸âƒ£ Run the GitHub Action
From the **Actions** tab, run **Train and Deploy Model** and provide:
- `project_name` â€“ your GCP project ID (must refer to an existing, globally unique GCP project ID)  
- `bucket` â€“ your Cloud Storage bucket name (must be globally unique across all of GCP)
- `region` â€“ (optional) default `us-central1`
- `model_name` â€“ (optional) default `idh-xgboost-model`

The workflow will automatically:
1. Enable Vertex AI / BigQuery APIs  
2. Prepare training data  
3. Train the model  
4. Deploy it to a Vertex AI endpoint  
5. Create a results artifact that can be downloaded from the workflow run.

---

## ğŸ’» Run the Gradio App Locally

To run the app locally after deploying your model to Vertex AI:

### 1ï¸âƒ£ Clone and install

```bash
git clone https://github.com/SamMaksoud8/idh-prediction.git
cd idh-prediction
pip install -e .
```

### 2ï¸âƒ£ Configure environment variables

Set your project-specific environment variables:

```bash
# Required
export PROJECT_NAME="idh-prediction"              # your GCP project ID
export BUCKET="idh-prototype-data"                # your Cloud Storage bucket (must be globally unique)

# Optional
export REGION="us-central1"                       # default region
export MODEL_NAME="idh-xgboost-model"             # optional Vertex AI model name`
```
> ğŸ’¡ These values should match the ones used during your GitHub Action deployment.

### 3ï¸âƒ£ Authenticate with Google Cloud

Point your environment to the service account key file you used for deployment:

```bash
export GOOGLE_APPLICATION_CREDENTIALS=".keys/idh-prediction.json"
```

If you haven't already authenticated for CLI use:

```bash
gcloud auth activate-service-account --key-file="$GOOGLE_APPLICATION_CREDENTIALS"
```

### 4ï¸âƒ£ Launch the Gradio app

```bash
python src/idh/app/csv_prediction.py
```

Visit <http://localhost:8080> to upload a dialysis CSV and view:

-   Systolic blood pressure (SBP) time-series plot

-   IDH risk prediction (âš ï¸ High / âœ… Low)

Example test files are available under `sample_data/`.

![Screenshot of the Gradio IDH prediction app](docs/assets/idh_gradio_overview.png)

---

## ğŸ§  For Reviewers

This project illustrates:
* MLOps automation using GitHub Actions and GCP APIs
* Cloud-native feature engineering via BigQuery SQL pipelines
* Vertex AI model lifecycle: training â†’ registry â†’ endpoint deployment
* Secure configuration with environment variables and secrets
* Human-centred ML UI for interpretability and validation

Itâ€™s intended as a portfolio demonstration of end-to-end ML engineering, not for clinical use.

## ğŸ—‚ï¸ Repository Structure
```bash
â”œâ”€â”€ config.yaml              # Default project/dataset/model config
â”œâ”€â”€ sample_data/             # Example dialysis session CSVs
â”œâ”€â”€ scripts/                 # CLI helpers for prep, training, deploy, predict
â”œâ”€â”€ src/idh/                 # Python package (data, model, gcp, app modules)
â””â”€â”€ requirements.txt         # Runtime dependencies
```

Key modules:
* idh.config â€“ loads YAML + .env overrides
* idh.data â€“ data ingestion & feature generation
* idh.model â€“ payload builders & Vertex AI inference helpers
* idh.gcp â€“ BigQuery / Storage utilities
* idh.app â€“ Gradio UI for predictions


## âš ï¸ Disclaimer

This repository is for educational and portfolio demonstration purposes only.
It is not a certified medical device and should not be used for clinical decision-making.
